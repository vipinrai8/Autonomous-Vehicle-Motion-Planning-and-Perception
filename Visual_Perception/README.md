# Visual Perception for Self-Driving Cars

![Cover](./media/cover.gif)


## Visual Features - Detection, Description and Matching

Visual features are used to track motion through an environment and to recognize places in a map. This module describes how features can be detected and tracked through a sequence of images and fused with other sources for localization as described in Course 2. Feature extraction is also fundamental to object detection and semantic segmentation in deep networks, and this module introduces some of the feature detection methods employed in that context as well.

- Programming Code: [Visual Odometry for Localization in Autonomous Driving](./Week_2/visual_odometry_for_localization_in_autonomous_driving.ipynb)
  - Output Files [output.yaml](./Week_2/output.yaml)

##  Perception of dynamic objects in the drivable region

The final module of this course focuses on the implementation of a collision warning system that alerts a self-driving car about the position and category of obstacles present in their lane. The project is comprised of three major segments: 1) Estimating the drivable space in 3D, 2) Semantic Lane Estimation and 3) Filter wrong output from object detection using semantic segmentation.

- Final Project: [Environment Perception For Self-Driving Cars](./Week_6/final_project)
  - Submission Files [output.yaml](./Week_6/output.yaml)


