# Visual Perception for Self-Driving Cars

![Cover](./media/cover.gif)

This part focuses on leveraging semantic segmentation neural networks to enhance self-driving car capabilities. Key tasks include implementing 3D drivable space estimation, lane estimation, and error filtering in 2D object detection. The integrated approach aims to improve obstacle detection and accurately determine their distance from the self-driving car, contributing to enhanced environmental awareness.
## Visual Features - Detection, Description and Matching

- Programming Code: [Visual Odometry for Localization in Autonomous Driving](https://github.com/vipinrai8/Autonomous-Vehicle-Motion-Planning-and-Perception/blob/main/Visual_Perception/Part1/Visual_Odometry_for_Localization_in_Autonomous_Driving.ipynb)
  - Output Files [output.yaml](https://github.com/vipinrai8/Autonomous-Vehicle-Motion-Planning-and-Perception/blob/main/Visual_Perception/Part1/output.yaml)

##  Perception of dynamic objects in the drivable region

- Final Project: [Environment Perception For Self-Driving Cars](https://github.com/vipinrai8/Autonomous-Vehicle-Motion-Planning-and-Perception/blob/main/Visual_Perception/Part2/final_project/Environment_Perception_For_Self_Driving_Cars_Learner.ipynb)
  - Submission Files [output.yaml](https://github.com/vipinrai8/Autonomous-Vehicle-Motion-Planning-and-Perception/tree/main/Visual_Perception/Part2/output.yaml)


